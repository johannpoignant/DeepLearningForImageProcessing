{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import random, os\n",
    "from models.alexnet import *\n",
    "from utils import *\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ConfigParser\n",
    "Config = ConfigParser.ConfigParser()\n",
    "Config.read(\"config.ini\")\n",
    "path_to_FOURVIERE_CLEAN2 = Config.get(\"Corpus\", 'path_to_FOURVIERE_CLEAN2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True #-- uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms.\n",
    "                       #-- If this is set to false, uses some in-built heuristics that might not always be fastest.\n",
    "\n",
    "cudnn.fastest = True #-- this is like the :fastest() mode for the Convolution modules,\n",
    "                     #-- simply picks the fastest convolution algorithm, rather than tuning for workspace size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "imSize = 225\n",
    "batchSize = 32\n",
    "nb_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathToImg = path_to_FOURVIERE_CLEAN2+\"IMAGE_FROM_V/\"\n",
    "\n",
    "# list imgaes\n",
    "pathImgTrain = [line.split(' ')[1] for line in open(path_to_FOURVIERE_CLEAN2+\"/cutTrainTest/u3_train.txt\").read().splitlines()]\n",
    "pathImgTest = [line.split(' ')[1] for line in open(path_to_FOURVIERE_CLEAN2+\"/cutTrainTest/u3_test_requestInTrain.txt\").read().splitlines()]\n",
    "\n",
    "ImgNameToClass = {line.split(' ')[1]:line.split(' ')[0] for line in open(path_to_FOURVIERE_CLEAN2+\"/cutTrainTest/u3_train.txt\").read().splitlines()}\n",
    "# add image from test\n",
    "ImgNameToClass.update({line.split(' ')[1]:line.split(' ')[0] for line in open(path_to_FOURVIERE_CLEAN2+\"/cutTrainTest/u3_test_requestInTrain.txt\").read().splitlines()})\n",
    "ClassToIdClass = {Artworks:i for i, Artworks in enumerate(sorted(set([line.split(' ')[0] for line in open(path_to_FOURVIERE_CLEAN2+\"/cutTrainTest/u3_train.txt\").read().splitlines()])))}\n",
    "ClassToIdClass.update({Artworks:i for i, Artworks in enumerate(sorted(set([line.split(' ')[0] for line in open(path_to_FOURVIERE_CLEAN2+\"/cutTrainTest/u3_test_requestInTrain.txt\").read().splitlines()])))})\n",
    "ImgNameToIdClass = {ImgName:ClassToIdClass[ImgNameToClass[ImgName]] for ImgName in  pathImgTrain}\n",
    "ImgNameToIdClass.update({ImgName:ClassToIdClass[ImgNameToClass[ImgName]] for ImgName in  pathImgTest})\n",
    "\n",
    "# load image in memory\n",
    "dImgTest = {imgName:Image.open(pathToImg+imgName).resize((imSize, imSize), Image.BILINEAR) for imgName in pathImgTest}\n",
    "dImgTrain = {imgName:Image.open(pathToImg+imgName) for imgName in pathImgTrain}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = ComputeMean(dImgTrain.values())\n",
    "std = ComputeStdDev(dImgTrain.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "imageTrainTransform = transforms.Compose([\n",
    "    transforms.Scale(300), \n",
    "    transforms.RandomCrop(225), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean = mean,\n",
    "                         std = std),\n",
    "])\n",
    "\n",
    "imageTestTransform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean = mean,\n",
    "                         std = std),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## test fixe features parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "copy Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "copy Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "copy Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "copy Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "alexTunedClassifier = alexnet(len(ImgNameToIdClass)).train()\n",
    "copyFeaturesParametersAlexnet(alexTunedClassifier, models.alexnet(pretrained=True))\n",
    "alexTunedClassifier = alexTunedClassifier.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 test : #Correct 174 on 624 (27.9%)\n",
      "epoch 1 test : #Correct 231 on 624 (37.0%)\n",
      "epoch 2 test : #Correct 197 on 624 (31.6%)\n",
      "epoch 3 test : #Correct 226 on 624 (36.2%)\n",
      "epoch 4 test : #Correct 238 on 624 (38.1%)\n",
      "epoch 5 test : #Correct 233 on 624 (37.3%)\n",
      "epoch 6 test : #Correct 217 on 624 (34.8%)\n",
      "epoch 7 test : #Correct 209 on 624 (33.5%)\n",
      "epoch 8 test : #Correct 231 on 624 (37.0%)\n",
      "epoch 9 test : #Correct 242 on 624 (38.8%)\n",
      "epoch 10 test : #Correct 241 on 624 (38.6%)\n",
      "epoch 11 test : #Correct 242 on 624 (38.8%)\n",
      "epoch 12 test : #Correct 225 on 624 (36.1%)\n",
      "epoch 13 test : #Correct 240 on 624 (38.5%)\n",
      "epoch 14 test : #Correct 243 on 624 (38.9%)\n",
      "epoch 15 test : #Correct 253 on 624 (40.5%)\n",
      "epoch 16 test : #Correct 225 on 624 (36.1%)\n",
      "epoch 17 test : #Correct 234 on 624 (37.5%)\n",
      "epoch 18 test : #Correct 258 on 624 (41.3%)\n",
      "epoch 19 test : #Correct 256 on 624 (41.0%)\n",
      "epoch 20 test : #Correct 242 on 624 (38.8%)\n",
      "epoch 21 test : #Correct 228 on 624 (36.5%)\n",
      "epoch 22 test : #Correct 260 on 624 (41.7%)\n",
      "epoch 23 test : #Correct 252 on 624 (40.4%)\n",
      "epoch 24 test : #Correct 243 on 624 (38.9%)\n",
      "epoch 25 test : #Correct 251 on 624 (40.2%)\n",
      "epoch 26 test : #Correct 248 on 624 (39.7%)\n",
      "epoch 27 test : #Correct 258 on 624 (41.3%)\n",
      "epoch 28 test : #Correct 255 on 624 (40.9%)\n",
      "epoch 29 test : #Correct 224 on 624 (35.9%)\n",
      "epoch 30 test : #Correct 238 on 624 (38.1%)\n",
      "epoch 31 test : #Correct 236 on 624 (37.8%)\n",
      "epoch 32 test : #Correct 243 on 624 (38.9%)\n",
      "epoch 33 test : #Correct 266 on 624 (42.6%)\n",
      "epoch 34 test : #Correct 243 on 624 (38.9%)\n",
      "epoch 35 test : #Correct 252 on 624 (40.4%)\n",
      "epoch 36 test : #Correct 260 on 624 (41.7%)\n",
      "epoch 37 test : #Correct 272 on 624 (43.6%)\n",
      "epoch 38 test : #Correct 238 on 624 (38.1%)\n",
      "epoch 39 test : #Correct 255 on 624 (40.9%)\n",
      "epoch 40 test : #Correct 251 on 624 (40.2%)\n",
      "epoch 41 test : #Correct 258 on 624 (41.3%)\n",
      "epoch 42 test : #Correct 280 on 624 (44.9%)\n",
      "epoch 43 test : #Correct 276 on 624 (44.2%)\n",
      "epoch 44 test : #Correct 272 on 624 (43.6%)\n",
      "epoch 45 test : #Correct 259 on 624 (41.5%)\n",
      "epoch 46 test : #Correct 258 on 624 (41.3%)\n",
      "epoch 47 test : #Correct 246 on 624 (39.4%)\n",
      "epoch 48 test : #Correct 260 on 624 (41.7%)\n",
      "epoch 49 test : #Correct 271 on 624 (43.4%)\n"
     ]
    }
   ],
   "source": [
    "#define the optimizer to only the classifier with lr of 1e-3\n",
    "optimizer=optim.SGD([{'params': alexTunedClassifier.classifier.parameters()},\n",
    "                     {'params': alexTunedClassifier.features.parameters(), 'lr': 0.0}\n",
    "                    ], lr=0.01, momentum=0.9)\n",
    "for epoch in range(50): \n",
    "    print \"epoch\", epoch, \n",
    "    trainclassifier(alexTunedClassifier, optimizer, criterion, batchSize, dImgTrain, imSize, imageTrainTransform, ImgNameToIdClass, 1)\n",
    "    testClassifier(alexTunedClassifier, dImgTest, imSize, imageTestTransform, ImgNameToIdClass, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "torch.save(alexTunedClassifier, \"alexFineTuned-50epoch-lr-0.01.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0 test : #Correct 281 on 624 (45.0%)\n",
      "epoch 1 test : #Correct 284 on 624 (45.5%)\n",
      "epoch 2 test : #Correct 289 on 624 (46.3%)\n",
      "epoch 3 test : #Correct 290 on 624 (46.5%)\n",
      "epoch 4 test : #Correct 290 on 624 (46.5%)\n",
      "epoch 5 test : #Correct 287 on 624 (46.0%)\n",
      "epoch 6 test : #Correct 288 on 624 (46.2%)\n",
      "epoch 7 test : #Correct 286 on 624 (45.8%)\n",
      "epoch 8 test : #Correct 289 on 624 (46.3%)\n",
      "epoch 9 test : #Correct 288 on 624 (46.2%)\n",
      "epoch 10 test : #Correct 289 on 624 (46.3%)\n",
      "epoch 11 test : #Correct 291 on 624 (46.6%)\n",
      "epoch 12 test : #Correct 291 on 624 (46.6%)\n",
      "epoch 13 test : #Correct 288 on 624 (46.2%)\n",
      "epoch 15 test : #Correct 289 on 624 (46.3%)\n",
      "epoch 16 test : #Correct 287 on 624 (46.0%)\n",
      "epoch 17 test : #Correct 293 on 624 (47.0%)\n",
      "epoch 18 test : #Correct 291 on 624 (46.6%)\n",
      "epoch 19 test : #Correct 295 on 624 (47.3%)\n",
      "epoch 20 test : #Correct 292 on 624 (46.8%)\n",
      "epoch 21 test : #Correct 293 on 624 (47.0%)\n",
      "epoch 22 test : #Correct 291 on 624 (46.6%)\n",
      "epoch 23 test : #Correct 293 on 624 (47.0%)\n",
      "epoch 24 test : #Correct 291 on 624 (46.6%)\n",
      "epoch 25 test : #Correct 288 on 624 (46.2%)\n",
      "epoch 26 test : #Correct 289 on 624 (46.3%)\n",
      "epoch 27 test : #Correct 293 on 624 (47.0%)\n",
      "epoch 28 test : #Correct 292 on 624 (46.8%)\n",
      "epoch 29 test : #Correct 287 on 624 (46.0%)\n",
      "epoch 30 test : #Correct 291 on 624 (46.6%)\n",
      "epoch 31 test : #Correct 291 on 624 (46.6%)\n",
      "epoch 32 test : #Correct 291 on 624 (46.6%)\n",
      "epoch 33 test : #Correct 289 on 624 (46.3%)\n",
      "epoch 34 test : #Correct 288 on 624 (46.2%)\n",
      "epoch 35 test : #Correct 286 on 624 (45.8%)\n",
      "epoch 36 test : #Correct 287 on 624 (46.0%)\n",
      "epoch 37 test : #Correct 293 on 624 (47.0%)\n",
      "epoch 38 test : #Correct 292 on 624 (46.8%)\n",
      "epoch 39 test : #Correct 292 on 624 (46.8%)\n",
      "epoch 40 test : #Correct 293 on 624 (47.0%)\n",
      "epoch 41 test : #Correct 292 on 624 (46.8%)\n",
      "epoch 42 test : #Correct 292 on 624 (46.8%)\n",
      "epoch 43 test : #Correct 290 on 624 (46.5%)\n",
      "epoch 44 test : #Correct 288 on 624 (46.2%)\n",
      "epoch 45 test : #Correct 290 on 624 (46.5%)\n",
      "epoch 46 test : #Correct 289 on 624 (46.3%)\n",
      "epoch 47 test : #Correct 288 on 624 (46.2%)\n",
      "epoch 48 test : #Correct 292 on 624 (46.8%)\n",
      "epoch 49 test : #Correct 291 on 624 (46.6%)\n"
     ]
    }
   ],
   "source": [
    "optimizer=optim.SGD([{'params': alexTunedClassifier.classifier.parameters()},\n",
    "                     {'params': alexTunedClassifier.features.parameters(), 'lr': 0.0}\n",
    "                    ], lr=0.001, momentum=0.9)\n",
    "for epoch in range(50): \n",
    "    print \"epoch\", epoch, \n",
    "    trainclassifier(alexTunedClassifier, optimizer, criterion, batchSize, dImgTrain, imSize, imageTrainTransform, ImgNameToIdClass, 1)\n",
    "    testClassifier(alexTunedClassifier, dImgTest, imSize, imageTestTransform, ImgNameToIdClass, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "torch.save(alexTunedClassifier, \"alexFineTuned-50epoch-lr-0.01-50epoch-lr-0.001.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "alexTunedClassifier = torch.load(\"alexFineTuned-50epoch-lr-0.01-50epoch-lr-0.001.ckpt\")\n",
    "alexTunedClassifier = alexTunedClassifier.cuda()\n",
    "\n",
    "optimizer=optim.SGD(alexTunedClassifier.parameters(), lr=0.01, momentum=0.9)\n",
    "for epoch in range(50): # loop over the dataset multiple times\n",
    "    print \"epoch\", epoch, \n",
    "    trainclassifier(alexTunedClassifier, optimizer, criterion, batchSize, dImgTrain, imSize, imageTrainTransform, ImgNameToIdClass, 1)\n",
    "    testClassifier(alexTunedClassifier, dImgTest, imSize, imageTestTransform, ImgNameToIdClass, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(alexTunedClassifier, \"alexFineTuned-50epoch-lr-0.01-50epoch-lr-0.001-50epoch-lr-0.01.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimizer=optim.SGD(alexTunedClassifier.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(50): \n",
    "    print \"epoch\", epoch, \n",
    "    trainclassifier(alexTunedClassifier, optimizer, criterion, batchSize, dImgTrain, imSize, imageTrainTransform, ImgNameToIdClass, 1)\n",
    "    testClassifier(alexTunedClassifier, dImgTest, imSize, imageTestTransform, ImgNameToIdClass, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "torch.save(alexTunedClassifier, \"alexFineTuned-50epoch-lr-0.01-50epoch-lr-0.001-50epoch-lr-0.01-50epoch-lr-0.001.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
