{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of fine tunning of an pre-trained AlexNet model on a new dataset for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "cudnn.benchmark = True #-- uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms.\n",
    "                       #-- If this is set to false, uses some in-built heuristics that might not always be fastest.\n",
    "\n",
    "cudnn.fastest = True #-- this is like the :fastest() mode for the Convolution modules,\n",
    "                     #-- simply picks the fastest convolution algorithm, rather than tuning for workspace size\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "\n",
    "import random, os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "from models.alexnet import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ConfigParser\n",
    "Config = ConfigParser.ConfigParser()\n",
    "Config.read(\"config.ini\")\n",
    "# path to the dataset\n",
    "path_to_FOURVIERE_CLEAN2 = Config.get(\"Corpus\", 'path_to_FOURVIERE_CLEAN2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "imSize = 225\n",
    "batchSize = 32\n",
    "nb_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load train and test data\n",
    "\n",
    "pathToImg = path_to_FOURVIERE_CLEAN2+\"IMAGE_FROM_V/\"\n",
    "# Dictionary with the imgName as key and corresponding class as value for the test and train part\n",
    "ImgNameToClassTrain = {line.split(' ')[1]:line.split(' ')[0] for line in open(path_to_FOURVIERE_CLEAN2+\"/cutTrainTest/u3_train.txt\").read().splitlines()}\n",
    "ImgNameToClassTest = {line.split(' ')[1]:line.split(' ')[0] for line in open(path_to_FOURVIERE_CLEAN2+\"/cutTrainTest/u3_test_requestInTrain.txt\").read().splitlines()}\n",
    "# Convert the class to a numeric id\n",
    "ClassToIdClassTrain = {Artworks:i for i, Artworks in enumerate(sorted(set([line.split(' ')[0] for line in open(path_to_FOURVIERE_CLEAN2+\"/cutTrainTest/u3_train.txt\").read().splitlines()])))}\n",
    "ClassToIdClassTest = {Artworks:i for i, Artworks in enumerate(sorted(set([line.split(' ')[0] for line in open(path_to_FOURVIERE_CLEAN2+\"/cutTrainTest/u3_test_requestInTrain.txt\").read().splitlines()])))}\n",
    "# Associate imgName to the corresponding numeric class id\n",
    "ImgNameToIdClassTrain = {ImgName:ClassToIdClass[ImgNameToClass[ImgName]] for ImgName in  ImgNameToClassTrain.keys()}\n",
    "ImgNameToIdClassTest = {ImgName:ClassToIdClass[ImgNameToClass[ImgName]] for ImgName in  ImgNameToClassTest.keys()}\n",
    "\n",
    "# open all images\n",
    "dImgTrain = {imgName:Image.open(pathToImg+imgName) for imgName in ImgNameToClassTrain.keys()}\n",
    "dImgTest = {imgName:Image.open(pathToImg+imgName).resize((imSize, imSize), Image.BILINEAR) for imgName in ImgNameToClassTest.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compute mean and standard deviation for images normalisation\n",
    "mean = ComputeMean(dImgTrain.values())\n",
    "std = ComputeStdDev(dImgTrain.values())\n",
    "\n",
    "imageTrainTransform = transforms.Compose([\n",
    "    transforms.Scale(300), \n",
    "    transforms.RandomCrop(225), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean = mean,\n",
    "                         std = std),\n",
    "])\n",
    "\n",
    "imageTestTransform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean = mean,\n",
    "                         std = std),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define the criterion\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fine tune alexNet with pretrained features parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "copy Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "copy Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "copy Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "copy Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "# defined a new net with the number of classes corresponding to the dataset\n",
    "alexTunedClassifier = alexnet(len(ImgNameToIdClass)).train()\n",
    "# load the pre-trained model and copy only the Features \n",
    "copyFeaturesParametersAlexnet(alexTunedClassifier, models.alexnet(pretrained=True))\n",
    "alexTunedClassifier = alexTunedClassifier.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 test : #Correct 174 on 624 (27.9%)\n",
      "epoch 1 test : #Correct 231 on 624 (37.0%)\n",
      "epoch 2 test : #Correct 197 on 624 (31.6%)\n",
      "epoch 3 test : #Correct 226 on 624 (36.2%)\n",
      "epoch 4 test : #Correct 238 on 624 (38.1%)\n",
      "epoch 5 test : #Correct 233 on 624 (37.3%)\n",
      "epoch 6 test : #Correct 217 on 624 (34.8%)\n",
      "epoch 7 test : #Correct 209 on 624 (33.5%)\n",
      "epoch 8 test : #Correct 231 on 624 (37.0%)\n",
      "epoch 9 test : #Correct 242 on 624 (38.8%)\n",
      "epoch 10 test : #Correct 241 on 624 (38.6%)\n",
      "epoch 11 test : #Correct 242 on 624 (38.8%)\n",
      "epoch 12 test : #Correct 225 on 624 (36.1%)\n",
      "epoch 13 test : #Correct 240 on 624 (38.5%)\n",
      "epoch 14 test : #Correct 243 on 624 (38.9%)\n",
      "epoch 15 test : #Correct 253 on 624 (40.5%)\n",
      "epoch 16 test : #Correct 225 on 624 (36.1%)\n",
      "epoch 17 test : #Correct 234 on 624 (37.5%)\n",
      "epoch 18 test : #Correct 258 on 624 (41.3%)\n",
      "epoch 19 test : #Correct 256 on 624 (41.0%)\n",
      "epoch 20 test : #Correct 242 on 624 (38.8%)\n",
      "epoch 21 test : #Correct 228 on 624 (36.5%)\n",
      "epoch 22 test : #Correct 260 on 624 (41.7%)\n",
      "epoch 23 test : #Correct 252 on 624 (40.4%)\n",
      "epoch 24 test : #Correct 243 on 624 (38.9%)\n",
      "epoch 25 test : #Correct 251 on 624 (40.2%)\n",
      "epoch 26 test : #Correct 248 on 624 (39.7%)\n",
      "epoch 27 test : #Correct 258 on 624 (41.3%)\n",
      "epoch 28 test : #Correct 255 on 624 (40.9%)\n",
      "epoch 29 test : #Correct 224 on 624 (35.9%)\n",
      "epoch 30 test : #Correct 238 on 624 (38.1%)\n",
      "epoch 31 test : #Correct 236 on 624 (37.8%)\n",
      "epoch 32 test : #Correct 243 on 624 (38.9%)\n",
      "epoch 33 test : #Correct 266 on 624 (42.6%)\n",
      "epoch 34 test : #Correct 243 on 624 (38.9%)\n",
      "epoch 35 test : #Correct 252 on 624 (40.4%)\n",
      "epoch 36 test : #Correct 260 on 624 (41.7%)\n",
      "epoch 37 test : #Correct 272 on 624 (43.6%)\n",
      "epoch 38 test : #Correct 238 on 624 (38.1%)\n",
      "epoch 39 test : #Correct 255 on 624 (40.9%)\n",
      "epoch 40 test : #Correct 251 on 624 (40.2%)\n",
      "epoch 41 test : #Correct 258 on 624 (41.3%)\n",
      "epoch 42 test : #Correct 280 on 624 (44.9%)\n",
      "epoch 43 test : #Correct 276 on 624 (44.2%)\n",
      "epoch 44 test : #Correct 272 on 624 (43.6%)\n",
      "epoch 45 test : #Correct 259 on 624 (41.5%)\n",
      "epoch 46 test : #Correct 258 on 624 (41.3%)\n",
      "epoch 47 test : #Correct 246 on 624 (39.4%)\n",
      "epoch 48 test : #Correct 260 on 624 (41.7%)\n",
      "epoch 49 test : #Correct 271 on 624 (43.4%)\n"
     ]
    }
   ],
   "source": [
    "#define the optimizer to train only the classifier part with lr of 0.01\n",
    "optimizer=optim.SGD([{'params': alexTunedClassifier.classifier.parameters()},\n",
    "                     {'params': alexTunedClassifier.features.parameters(), 'lr': 0.0}\n",
    "                    ], lr=0.01, momentum=0.9)\n",
    "for epoch in range(50): \n",
    "    print \"epoch\", epoch, \n",
    "    trainclassifier(alexTunedClassifier, optimizer, criterion, batchSize, dImgTrain, imSize, imageTrainTransform, ImgNameToIdClass, 1)\n",
    "    testClassifier(alexTunedClassifier, dImgTest, imSize, imageTestTransform, ImgNameToIdClass, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save the net\n",
    "torch.save(alexTunedClassifier, \"alexFineTuned-50epoch-lr-0.01.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the model and define the optimizer to train only the classifier part with lr of 0.001\n",
    "alexTunedClassifier = torch.load(\"alexFineTuned-50epoch-lr-0.01.ckpt\")\n",
    "alexTunedClassifier = alexTunedClassifier.cuda()\n",
    "\n",
    "optimizer=optim.SGD([{'params': alexTunedClassifier.classifier.parameters()},\n",
    "                     {'params': alexTunedClassifier.features.parameters(), 'lr': 0.0}\n",
    "                    ], lr=0.001, momentum=0.9)\n",
    "for epoch in range(50): \n",
    "    print \"epoch\", epoch, \n",
    "    trainclassifier(alexTunedClassifier, optimizer, criterion, batchSize, dImgTrain, imSize, imageTrainTransform, ImgNameToIdClass, 1)\n",
    "    testClassifier(alexTunedClassifier, dImgTest, imSize, imageTestTransform, ImgNameToIdClass, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save the net\n",
    "torch.save(alexTunedClassifier, \"alexFineTuned-50epoch-lr-0.01-50epoch-lr-0.001.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the model and define the optimizer to train net with lr of 0.01\n",
    "alexTunedClassifier = torch.load(\"alexFineTuned-50epoch-lr-0.01-50epoch-lr-0.001.ckpt\")\n",
    "alexTunedClassifier = alexTunedClassifier.cuda()\n",
    "\n",
    "optimizer=optim.SGD(alexTunedClassifier.parameters(), lr=0.01, momentum=0.9)\n",
    "for epoch in range(50): # loop over the dataset multiple times\n",
    "    print \"epoch\", epoch, \n",
    "    trainclassifier(alexTunedClassifier, optimizer, criterion, batchSize, dImgTrain, imSize, imageTrainTransform, ImgNameToIdClass, 1)\n",
    "    testClassifier(alexTunedClassifier, dImgTest, imSize, imageTestTransform, ImgNameToIdClass, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the net\n",
    "torch.save(alexTunedClassifier, \"alexFineTuned-50epoch-lr-0.01-50epoch-lr-0.001-50epoch-lr-0.01.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the model and define the optimizer to train net with lr of 0.001\n",
    "optimizer=optim.SGD(alexTunedClassifier.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(50): \n",
    "    print \"epoch\", epoch, \n",
    "    trainclassifier(alexTunedClassifier, optimizer, criterion, batchSize, dImgTrain, imSize, imageTrainTransform, ImgNameToIdClass, 1)\n",
    "    testClassifier(alexTunedClassifier, dImgTest, imSize, imageTestTransform, ImgNameToIdClass, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save the net\n",
    "torch.save(alexTunedClassifier, \"alexFineTuned-50epoch-lr-0.01-50epoch-lr-0.001-50epoch-lr-0.01-50epoch-lr-0.001.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
