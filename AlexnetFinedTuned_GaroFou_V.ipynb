{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of fine tunning of an pre-trained AlexNet model on a new dataset for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "cudnn.benchmark = True #-- uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms.\n",
    "                       #-- If this is set to false, uses some in-built heuristics that might not always be fastest.\n",
    "\n",
    "cudnn.fastest = True #-- this is like the :fastest() mode for the Convolution modules,\n",
    "                     #-- simply picks the fastest convolution algorithm, rather than tuning for workspace size\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "\n",
    "import random, os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "from models.alexnet import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ConfigParser\n",
    "Config = ConfigParser.ConfigParser()\n",
    "Config.read(\"config.ini\")\n",
    "# path to the dataset\n",
    "path_to_FOURVIERE_CLEAN2 = Config.get(\"Corpus\", 'path_to_FOURVIERE_CLEAN2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "imSize = 225\n",
    "batchSize = 32\n",
    "nb_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'ImgNameToClass' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dde2034bc0e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mClassToIdClassTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mArtworks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArtworks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_FOURVIERE_CLEAN2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cutTrainTest/u3_test_requestInTrain.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Associate imgName to the corresponding numeric class id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mImgNameToIdClassTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mImgName\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mClassToIdClassTrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mImgNameToClass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mImgName\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mImgName\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mImgNameToClassTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mImgNameToIdClassTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mImgName\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mClassToIdClassTest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mImgNameToClass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mImgName\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mImgName\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mImgNameToClassTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-dde2034bc0e4>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m((ImgName,))\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mClassToIdClassTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mArtworks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArtworks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_FOURVIERE_CLEAN2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cutTrainTest/u3_test_requestInTrain.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Associate imgName to the corresponding numeric class id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mImgNameToIdClassTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mImgName\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mClassToIdClassTrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mImgNameToClass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mImgName\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mImgName\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mImgNameToClassTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mImgNameToIdClassTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mImgName\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mClassToIdClassTest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mImgNameToClass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mImgName\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mImgName\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mImgNameToClassTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'ImgNameToClass' is not defined"
     ]
    }
   ],
   "source": [
    "# Load train and test data\n",
    "\n",
    "pathToImg = path_to_FOURVIERE_CLEAN2+\"IMAGE_FROM_V/\"\n",
    "# Dictionary with the imgName as key and corresponding class as value for the test and train part\n",
    "ImgNameToClassTrain = {line.split(' ')[1]:line.split(' ')[0] for line in open(path_to_FOURVIERE_CLEAN2+\"/cutTrainTest/u3_train.txt\").read().splitlines()}\n",
    "ImgNameToClassTest = {line.split(' ')[1]:line.split(' ')[0] for line in open(path_to_FOURVIERE_CLEAN2+\"/cutTrainTest/u3_test_requestInTrain.txt\").read().splitlines()}\n",
    "# Convert the class to a numeric id\n",
    "ClassToIdClassTrain = {Artworks:i for i, Artworks in enumerate(sorted(set([line.split(' ')[0] for line in open(path_to_FOURVIERE_CLEAN2+\"/cutTrainTest/u3_train.txt\").read().splitlines()])))}\n",
    "ClassToIdClassTest = {Artworks:i for i, Artworks in enumerate(sorted(set([line.split(' ')[0] for line in open(path_to_FOURVIERE_CLEAN2+\"/cutTrainTest/u3_test_requestInTrain.txt\").read().splitlines()])))}\n",
    "# Associate imgName to the corresponding numeric class id\n",
    "ImgNameToIdClassTrain = {ImgName:ClassToIdClassTrain[ImgNameToClassTrain[ImgName]] for ImgName in  ImgNameToClassTrain.keys()}\n",
    "ImgNameToIdClassTest = {ImgName:ClassToIdClassTest[ImgNameToClassTest[ImgName]] for ImgName in  ImgNameToClassTest.keys()}\n",
    "\n",
    "# open all images\n",
    "dImgTrain = {imgName:Image.open(pathToImg+imgName) for imgName in ImgNameToClassTrain.keys()}\n",
    "dImgTest = {imgName:Image.open(pathToImg+imgName).resize((imSize, imSize), Image.BILINEAR) for imgName in ImgNameToClassTest.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compute mean and standard deviation for images normalisation\n",
    "mean = ComputeMean(dImgTrain.values())\n",
    "std = ComputeStdDev(dImgTrain.values())\n",
    "\n",
    "imageTrainTransform = transforms.Compose([\n",
    "    transforms.Scale(300), \n",
    "    transforms.RandomCrop(225), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean = mean,\n",
    "                         std = std),\n",
    "])\n",
    "\n",
    "imageTestTransform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean = mean,\n",
    "                         std = std),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define the criterion\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fine tune alexNet with pretrained features parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# defined a new net with the number of classes corresponding to the dataset\n",
    "alexTunedClassifier = alexnet(len(ImgNameToIdClass)).train()\n",
    "# load the pre-trained model and copy only the Features \n",
    "copyFeaturesParametersAlexnet(alexTunedClassifier, models.alexnet(pretrained=True))\n",
    "alexTunedClassifier = alexTunedClassifier.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#define the optimizer to train only the classifier part with lr of 0.01\n",
    "optimizer=optim.SGD([{'params': alexTunedClassifier.classifier.parameters()},\n",
    "                     {'params': alexTunedClassifier.features.parameters(), 'lr': 0.0}\n",
    "                    ], lr=0.01, momentum=0.9)\n",
    "for epoch in range(50): \n",
    "    print \"epoch\", epoch, \n",
    "    trainclassifier(alexTunedClassifier, optimizer, criterion, batchSize, dImgTrain, imSize, imageTrainTransform, ImgNameToIdClass, 1)\n",
    "    testClassifier(alexTunedClassifier, dImgTest, imSize, imageTestTransform, ImgNameToIdClass, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save the net\n",
    "torch.save(alexTunedClassifier, \"alexFineTuned-50epoch-lr-0.01.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the model and define the optimizer to train only the classifier part with lr of 0.001\n",
    "alexTunedClassifier = torch.load(\"alexFineTuned-50epoch-lr-0.01.ckpt\")\n",
    "alexTunedClassifier = alexTunedClassifier.cuda()\n",
    "\n",
    "optimizer=optim.SGD([{'params': alexTunedClassifier.classifier.parameters()},\n",
    "                     {'params': alexTunedClassifier.features.parameters(), 'lr': 0.0}\n",
    "                    ], lr=0.001, momentum=0.9)\n",
    "for epoch in range(50): \n",
    "    print \"epoch\", epoch, \n",
    "    trainclassifier(alexTunedClassifier, optimizer, criterion, batchSize, dImgTrain, imSize, imageTrainTransform, ImgNameToIdClass, 1)\n",
    "    testClassifier(alexTunedClassifier, dImgTest, imSize, imageTestTransform, ImgNameToIdClass, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save the net\n",
    "torch.save(alexTunedClassifier, \"alexFineTuned-50epoch-lr-0.01-50epoch-lr-0.001.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the model and define the optimizer to train net with lr of 0.01\n",
    "alexTunedClassifier = torch.load(\"alexFineTuned-50epoch-lr-0.01-50epoch-lr-0.001.ckpt\")\n",
    "alexTunedClassifier = alexTunedClassifier.cuda()\n",
    "\n",
    "optimizer=optim.SGD(alexTunedClassifier.parameters(), lr=0.01, momentum=0.9)\n",
    "for epoch in range(50): # loop over the dataset multiple times\n",
    "    print \"epoch\", epoch, \n",
    "    trainclassifier(alexTunedClassifier, optimizer, criterion, batchSize, dImgTrain, imSize, imageTrainTransform, ImgNameToIdClass, 1)\n",
    "    testClassifier(alexTunedClassifier, dImgTest, imSize, imageTestTransform, ImgNameToIdClass, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the net\n",
    "torch.save(alexTunedClassifier, \"alexFineTuned-50epoch-lr-0.01-50epoch-lr-0.001-50epoch-lr-0.01.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the model and define the optimizer to train net with lr of 0.001\n",
    "optimizer=optim.SGD(alexTunedClassifier.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(50): \n",
    "    print \"epoch\", epoch, \n",
    "    trainclassifier(alexTunedClassifier, optimizer, criterion, batchSize, dImgTrain, imSize, imageTrainTransform, ImgNameToIdClass, 1)\n",
    "    testClassifier(alexTunedClassifier, dImgTest, imSize, imageTestTransform, ImgNameToIdClass, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save the net\n",
    "torch.save(alexTunedClassifier, \"alexFineTuned-50epoch-lr-0.01-50epoch-lr-0.001-50epoch-lr-0.01-50epoch-lr-0.001.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
