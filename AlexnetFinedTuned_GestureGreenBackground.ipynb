{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "cudnn.benchmark = True #-- uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms.\n",
    "                       #-- If this is set to false, uses some in-built heuristics that might not always be fastest.\n",
    "\n",
    "cudnn.fastest = True #-- this is like the :fastest() mode for the Convolution modules,\n",
    "                     #-- simply picks the fastest convolution algorithm, rather than tuning for workspace size\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "\n",
    "import random, os, glob\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "from models.alexnet import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import ConfigParser\n",
    "Config = ConfigParser.ConfigParser()\n",
    "Config.read(\"config.ini\")\n",
    "# path to the dataset\n",
    "path_to_GreenBackground = Config.get(\"Corpus\", 'path_to_GreenBackground')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mrim/data/collection/GUIMUTEIC/Gesture/Green_background/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_GreenBackground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "imSize = 225\n",
    "batchSize = 32\n",
    "nb_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load train and test data\n",
    "\n",
    "userTestSet = ['C', 'D', 'E']\n",
    "userTrainSet = ['F', 'G', 'H', 'I', 'J', 'K']\n",
    "\n",
    "# Dictionary with the imgName as key and corresponding class as value for the test and train part\n",
    "ImgNameToClassTrain = {}\n",
    "for user in userTrainSet:\n",
    "    for img in glob.glob(path_to_GreenBackground+user+'/img/*'):\n",
    "        ImgNameToClassTrain[img]=img.split('_')[-2]\n",
    "ImgNameToClassTest = {}\n",
    "for user in userTestSet:\n",
    "    for img in glob.glob(path_to_GreenBackground+user+'/img/*'):\n",
    "        ImgNameToClassTest[img]=img.split('_')[-2]\n",
    "# Convert the class to a numeric id\n",
    "ClassToIdClass ={'1':0, '2':1, '3':2, '4':3, '5':4}        \n",
    "# Associate imgName to the corresponding numeric class id\n",
    "ImgNameToIdClassTrain = {ImgName:ClassToIdClass[ImgNameToClassTrain[ImgName]] for ImgName in  ImgNameToClassTrain.keys()}\n",
    "ImgNameToIdClassTest = {ImgName:ClassToIdClass[ImgNameToClassTest[ImgName]] for ImgName in  ImgNameToClassTest.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/mrim/data/collection/GUIMUTEIC/Gesture/Green_background//home/mrim/data/collection/GUIMUTEIC/Gesture/Green_background/G/img/indoor_office_2_973.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a608076204c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdImgTrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mimgName\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_GreenBackground\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimgName\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimgName\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mImgNameToClassTrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdImgTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mimgName\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_GreenBackground\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimgName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBILINEAR\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimgName\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mImgNameToClassTest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-a608076204c5>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m((imgName,))\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdImgTrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mimgName\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_GreenBackground\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimgName\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimgName\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mImgNameToClassTrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdImgTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mimgName\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_GreenBackground\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimgName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBILINEAR\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimgName\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mImgNameToClassTest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2411\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/mrim/data/collection/GUIMUTEIC/Gesture/Green_background//home/mrim/data/collection/GUIMUTEIC/Gesture/Green_background/G/img/indoor_office_2_973.jpg'"
     ]
    }
   ],
   "source": [
    "dImgTrain = {imgName:Image.open(imgName) for imgName in ImgNameToClassTrain.keys()}\n",
    "dImgTest = {imgName:Image.open(imgName).resize((imSize, imSize), Image.BILINEAR) for imgName in ImgNameToClassTest.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compute mean and standard deviation for images normalisation\n",
    "mean = ComputeMean(dImgTrain.values())\n",
    "std = ComputeStdDev(dImgTrain.values())\n",
    "\n",
    "imageTrainTransform = transforms.Compose([\n",
    "    transforms.Scale(300), \n",
    "    transforms.RandomCrop(225), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean = mean,\n",
    "                         std = std),\n",
    "])\n",
    "\n",
    "imageTestTransform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean = mean,\n",
    "                         std = std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define the criterion\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# defined a new net with the number of classes corresponding to the dataset\n",
    "alexTunedClassifier = alexnet(len(ImgNameToIdClassTrain)).train()\n",
    "# load the pre-trained model and copy only the Features \n",
    "copyFeaturesParametersAlexnet(alexTunedClassifier, models.alexnet(pretrained=True))\n",
    "alexTunedClassifier = alexTunedClassifier.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#define the optimizer to train only the classifier part with lr of 0.01\n",
    "optimizer=optim.SGD([{'params': alexTunedClassifier.classifier.parameters()},\n",
    "                     {'params': alexTunedClassifier.features.parameters(), 'lr': 0.0}\n",
    "                    ], lr=0.01, momentum=0.9)\n",
    "for epoch in range(50): \n",
    "    print \"epoch\", epoch, \n",
    "    trainclassifier(alexTunedClassifier, optimizer, criterion, batchSize, dImgTrain, imSize, imageTrainTransform, ImgNameToIdClassTrain, 1)\n",
    "    testClassifier(alexTunedClassifier, dImgTest, imSize, imageTestTransform, ImgNameToIdClassTest, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save the net\n",
    "torch.save(alexTunedClassifier, \"ckpt/gesture_alexFineTuned-50epoch-lr-0.01.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the model and define the optimizer to train only the classifier part with lr of 0.001\n",
    "alexTunedClassifier = torch.load(\"ckpt/gesture_alexFineTuned-50epoch-lr-0.01.ckpt\")\n",
    "alexTunedClassifier = alexTunedClassifier.cuda()\n",
    "\n",
    "optimizer=optim.SGD([{'params': alexTunedClassifier.classifier.parameters()},\n",
    "                     {'params': alexTunedClassifier.features.parameters(), 'lr': 0.0}\n",
    "                    ], lr=0.001, momentum=0.9)\n",
    "for epoch in range(50): \n",
    "    print \"epoch\", epoch, \n",
    "    trainclassifier(alexTunedClassifier, optimizer, criterion, batchSize, dImgTrain, imSize, imageTrainTransform, ImgNameToIdClassTrain, 1)\n",
    "    testClassifier(alexTunedClassifier, dImgTest, imSize, imageTestTransform, ImgNameToIdClassTest, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save the net\n",
    "torch.save(alexTunedClassifier, \"ckpt/gesture_alexFineTuned-50epoch-lr-0.01-50epoch-lr-0.001.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the model and define the optimizer to train net with lr of 0.01\n",
    "alexTunedClassifier = torch.load(\"ckpt/gesture_alexFineTuned-50epoch-lr-0.01-50epoch-lr-0.001.ckpt\")\n",
    "alexTunedClassifier = alexTunedClassifier.cuda()\n",
    "\n",
    "optimizer=optim.SGD(alexTunedClassifier.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(50): # loop over the dataset multiple times\n",
    "    print \"epoch\", epoch, \n",
    "    trainclassifier(alexTunedClassifier, optimizer, criterion, batchSize, dImgTrain, imSize, imageTrainTransform, ImgNameToIdClassTrain, 1)\n",
    "    testClassifier(alexTunedClassifier, dImgTest, imSize, imageTestTransform, ImgNameToIdClassTest, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# save the net\n",
    "torch.save(alexTunedClassifier, \"ckpt/gesture_alexFineTuned-50epoch-lr-0.01-50epoch-lr-0.001-50epoch-lr-0.001.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the model and define the optimizer to train net with lr of 0.001\n",
    "optimizer=optim.SGD(alexTunedClassifier.parameters(), lr=0.0001, momentum=0.9)\n",
    "for epoch in range(50): \n",
    "    print \"epoch\", epoch, \n",
    "    trainclassifier(alexTunedClassifier, optimizer, criterion, batchSize, dImgTrain, imSize, imageTrainTransform, ImgNameToIdClassTrain, 1)\n",
    "    testClassifier(alexTunedClassifier, dImgTest, imSize, imageTestTransform, ImgNameToIdClassTest, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save the net\n",
    "torch.save(alexTunedClassifier, \"ckpt/gesture_alexFineTuned-50epoch-lr-0.01-50epoch-lr-0.001-50epoch-lr-0.001-50epoch-lr-0.0001.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
